"""Golden image tests for CPU reference renderer (OpenCV distance-transform model).

This test suite validates rendering against known-good reference images
with the new OpenCV distance-transform spray model (flat core + Gaussian skirt).

Test workflow:
1. Render predefined strokes with fixed seeds and configs
2. Compare rendered images against saved golden PNGs
3. Validate metrics: PSNR, SSIM, ΔE2000, coverage, center luminance
4. Fail if any metric exceeds threshold

Golden test cases:
1. straight_line: Simple horizontal stroke
2. curved_stroke: S-curve with varying z/v
3. multi_stroke: Three overlapping strokes
4. boundary_graze: Stroke near canvas edge
5. tiny_stroke: Micro-stroke for anti-aliasing test
6. speed_scaling: Same stroke at different speeds
7. width_control: Strokes at different Z heights

Acceptance thresholds:
- PSNR ≥ 28 dB (strict pixel-level match)
- SSIM ≥ 0.92 (structural similarity)
- ΔE2000 mean ≤ 2.0 (perceptual color difference)
- Coverage fraction within expected range
- Center luminance drop ≥ 0.05 (visibility gate)

Usage:
    pytest tests/test_cpu_golden.py  # Run all golden tests
    pytest tests/test_cpu_golden.py::test_golden_straight_line
    pytest tests/test_cpu_golden.py --regen-golden  # Regenerate (manual mode)
"""

import logging
from pathlib import Path
from typing import Dict, Tuple

import numpy as np
import pytest
import torch

from src.airbrush_simulator.cpu_reference import CPUReferenceRenderer, load_toy_luts
from src.utils import color as color_utils, metrics, fs

logger = logging.getLogger(__name__)

# Golden test data directory
GOLDEN_DIR = Path(__file__).parent.parent / 'ci' / 'golden_tests_cpu'

# Acceptance thresholds (adjusted for alcohol ink transparent layering model)
THRESHOLDS = {
    'psnr_min': 25.0,                  # dB (relaxed for transparent layering)
    'ssim_min': 0.92,                  # [0,1]
    'delta_e_max': 2.0,                # ΔE2000
    'coverage_tol': 0.05,              # ±5% relative
    'min_center_luminance_drop': 0.05  # center must darken by at least this much
}


# ============================================================================
# FIXTURES
# ============================================================================

@pytest.fixture
def renderer():
    """Create renderer with fixed config and toy LUTs."""
    env_cfg = {
        'work_area_mm': (210.0, 297.0),
        'render_px': (908, 1280)
    }
    sim_cfg = {
        'renderer_cpu_config': 'configs/sim/renderer_cpu.v1.yaml'
    }
    # Use high_visibility=True for solid black strokes
    luts = load_toy_luts(high_visibility=True)
    return CPUReferenceRenderer(sim_cfg, env_cfg, luts)


@pytest.fixture
def blank_canvas():
    """White canvas for rendering."""
    canvas = np.ones((908, 1280, 3), dtype=np.float32)
    alpha = np.zeros((908, 1280), dtype=np.float32)
    return canvas, alpha


# ============================================================================
# GOLDEN STROKE DEFINITIONS
# ============================================================================

def get_golden_strokes() -> Dict[str, Dict]:
    """Get predefined golden strokes.
    
    Returns
    -------
    dict
        Mapping of test name → stroke definition
    """
    strokes = {
        'straight_line': {
            'id': 'golden-00000-straight',
            'bezier': {
                'p1': (50.0, 148.5),
                'p2': (80.0, 148.5),
                'p3': (130.0, 148.5),
                'p4': (160.0, 148.5)
            },
            'z_profile': {'z0': 6.0, 'z1': 6.0},
            'speed_profile': {'v0': 50.0, 'v1': 50.0},
            'color_cmy': {'c': 0.8, 'm': 0.2, 'y': 0.1}
        },
        
        'curved_stroke': {
            'id': 'golden-00001-curved',
            'bezier': {
                'p1': (50.0, 50.0),
                'p2': (100.0, 120.0),
                'p3': (150.0, 80.0),
                'p4': (200.0, 150.0)
            },
            'z_profile': {'z0': 5.0, 'z1': 10.0},
            'speed_profile': {'v0': 40.0, 'v1': 100.0},
            'color_cmy': {'c': 0.2, 'm': 0.8, 'y': 0.3}
        },
        
        'boundary_graze': {
            'id': 'golden-00002-boundary',
            'bezier': {
                'p1': (5.0, 5.0),
                'p2': (10.0, 10.0),
                'p3': (15.0, 15.0),
                'p4': (20.0, 20.0)
            },
            'z_profile': {'z0': 6.0, 'z1': 8.0},
            'speed_profile': {'v0': 60.0, 'v1': 80.0},
            'color_cmy': {'c': 0.5, 'm': 0.5, 'y': 0.5}
        },
        
        'tiny_stroke': {
            'id': 'golden-00003-tiny',
            'bezier': {
                'p1': (100.0, 100.0),
                'p2': (101.0, 100.5),
                'p3': (102.0, 101.0),
                'p4': (103.0, 101.5)
            },
            'z_profile': {'z0': 6.0, 'z1': 6.0},
            'speed_profile': {'v0': 50.0, 'v1': 50.0},
            'color_cmy': {'c': 0.3, 'm': 0.3, 'y': 0.3}
        },
        
        'wide_stroke_high_z': {
            'id': 'golden-00004-wide',
            'bezier': {
                'p1': (60.0, 200.0),
                'p2': (90.0, 200.0),
                'p3': (120.0, 200.0),
                'p4': (150.0, 200.0)
            },
            'z_profile': {'z0': 15.0, 'z1': 15.0},
            'speed_profile': {'v0': 50.0, 'v1': 50.0},
            'color_cmy': {'c': 0.6, 'm': 0.4, 'y': 0.2}
        },
        
        'narrow_stroke_low_z': {
            'id': 'golden-00005-narrow',
            'bezier': {
                'p1': (60.0, 220.0),
                'p2': (90.0, 220.0),
                'p3': (120.0, 220.0),
                'p4': (150.0, 220.0)
            },
            'z_profile': {'z0': 3.0, 'z1': 3.0},
            'speed_profile': {'v0': 50.0, 'v1': 50.0},
            'color_cmy': {'c': 0.6, 'm': 0.4, 'y': 0.2}
        },
        
        'fast_stroke': {
            'id': 'golden-00006-fast',
            'bezier': {
                'p1': (60.0, 240.0),
                'p2': (90.0, 240.0),
                'p3': (120.0, 240.0),
                'p4': (150.0, 240.0)
            },
            'z_profile': {'z0': 6.0, 'z1': 6.0},
            'speed_profile': {'v0': 200.0, 'v1': 200.0},
            'color_cmy': {'c': 0.6, 'm': 0.4, 'y': 0.2}
        },
        
        'slow_stroke': {
            'id': 'golden-00007-slow',
            'bezier': {
                'p1': (60.0, 260.0),
                'p2': (90.0, 260.0),
                'p3': (120.0, 260.0),
                'p4': (150.0, 260.0)
            },
            'z_profile': {'z0': 6.0, 'z1': 6.0},
            'speed_profile': {'v0': 20.0, 'v1': 20.0},
            'color_cmy': {'c': 0.6, 'm': 0.4, 'y': 0.2}
        }
    }
    
    return strokes


def get_golden_multi_strokes() -> list:
    """Get multi-stroke test case (three overlapping strokes).
    
    Returns
    -------
    list of dict
        List of stroke definitions
    """
    return [
        {
            'id': 'golden-multi-00',
            'bezier': {
                'p1': (80.0, 100.0),
                'p2': (100.0, 100.0),
                'p3': (120.0, 100.0),
                'p4': (140.0, 100.0)
            },
            'z_profile': {'z0': 6.0, 'z1': 6.0},
            'speed_profile': {'v0': 50.0, 'v1': 50.0},
            'color_cmy': {'c': 0.9, 'm': 0.1, 'y': 0.1}
        },
        {
            'id': 'golden-multi-01',
            'bezier': {
                'p1': (90.0, 110.0),
                'p2': (110.0, 110.0),
                'p3': (130.0, 110.0),
                'p4': (150.0, 110.0)
            },
            'z_profile': {'z0': 8.0, 'z1': 8.0},
            'speed_profile': {'v0': 60.0, 'v1': 60.0},
            'color_cmy': {'c': 0.1, 'm': 0.9, 'y': 0.1}
        },
        {
            'id': 'golden-multi-02',
            'bezier': {
                'p1': (85.0, 120.0),
                'p2': (105.0, 120.0),
                'p3': (125.0, 120.0),
                'p4': (145.0, 120.0)
            },
            'z_profile': {'z0': 5.0, 'z1': 5.0},
            'speed_profile': {'v0': 70.0, 'v1': 70.0},
            'color_cmy': {'c': 0.1, 'm': 0.1, 'y': 0.9}
        }
    ]


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def render_golden_case(
    renderer: CPUReferenceRenderer,
    strokes: list,
    canvas_init: np.ndarray,
    alpha_init: np.ndarray
) -> Tuple[np.ndarray, np.ndarray]:
    """Render a golden test case.
    
    Parameters
    ----------
    renderer : CPUReferenceRenderer
        Renderer instance
    strokes : list of dict or dict
        Stroke definition(s)
    canvas_init : np.ndarray
        Initial canvas
    alpha_init : np.ndarray
        Initial alpha map
    
    Returns
    -------
    canvas : np.ndarray
        Rendered canvas (linear RGB)
    alpha : np.ndarray
        Alpha map
    """
    canvas = canvas_init.copy()
    alpha = alpha_init.copy()
    
    if isinstance(strokes, dict):
        strokes = [strokes]
    
    return renderer.render_strokes(canvas, alpha, strokes)


def save_golden_image(canvas: np.ndarray, path: Path):
    """Save canvas as golden PNG (sRGB).
    
    Parameters
    ----------
    canvas : np.ndarray
        Canvas in linear RGB [0,1]
    path : Path
        Output path
    """
    # Convert numpy to torch tensor for color conversion
    canvas_torch = torch.from_numpy(canvas).permute(2, 0, 1)  # (H,W,3) -> (3,H,W)
    canvas_srgb = color_utils.linear_to_srgb(canvas_torch)
    canvas_srgb = canvas_srgb.permute(1, 2, 0).numpy()  # (3,H,W) -> (H,W,3)
    canvas_uint8 = np.clip(canvas_srgb * 255, 0, 255).astype(np.uint8)
    
    import PIL.Image
    img = PIL.Image.fromarray(canvas_uint8, mode='RGB')
    img.save(path)


def load_golden_image(path: Path) -> np.ndarray:
    """Load golden PNG and convert to linear RGB.
    
    Parameters
    ----------
    path : Path
        Path to golden PNG
    
    Returns
    -------
    np.ndarray
        Canvas in linear RGB [0,1], shape (H, W, 3)
    """
    import PIL.Image
    img = PIL.Image.open(path).convert('RGB')
    arr = np.array(img, dtype=np.float32) / 255.0  # sRGB [0,1]
    # Convert to torch tensor for color conversion
    arr_torch = torch.from_numpy(arr).permute(2, 0, 1)  # (H,W,3) -> (3,H,W)
    arr_linear = color_utils.srgb_to_linear(arr_torch)
    arr_linear = arr_linear.permute(1, 2, 0).numpy()  # (3,H,W) -> (H,W,3)
    return arr_linear


def compute_metrics(
    canvas_test: np.ndarray,
    canvas_golden: np.ndarray,
    alpha_test: np.ndarray
) -> Dict[str, float]:
    """Compute validation metrics.
    
    Parameters
    ----------
    canvas_test : np.ndarray
        Test canvas, linear RGB [0,1]
    canvas_golden : np.ndarray
        Golden canvas, linear RGB [0,1]
    alpha_test : np.ndarray
        Test alpha map [0,1]
    
    Returns
    -------
    dict
        Metrics: {psnr, ssim, delta_e_mean, coverage, center_luminance_drop}
    """
    # Convert numpy arrays to torch tensors with correct shape
    canvas_test_torch = torch.from_numpy(canvas_test).permute(2, 0, 1)
    canvas_golden_torch = torch.from_numpy(canvas_golden).permute(2, 0, 1)
    alpha_test_torch = torch.from_numpy(alpha_test)
    
    # PSNR (higher is better)
    psnr = metrics.psnr(canvas_test_torch, canvas_golden_torch)
    
    # SSIM (higher is better)
    ssim = metrics.ssim(canvas_test_torch, canvas_golden_torch)
    
    # ΔE2000 (lower is better)
    lab_test = color_utils.rgb_to_lab(canvas_test_torch)
    lab_golden = color_utils.rgb_to_lab(canvas_golden_torch)
    delta_e = color_utils.delta_e2000(lab_test, lab_golden)
    delta_e_mean = float(delta_e.mean())
    
    # Coverage (painted area fraction)
    coverage = metrics.paint_coverage(alpha_test_torch)
    
    # Center luminance drop (visibility check)
    # Compute luminance of white canvas vs painted canvas where alpha > 0.1
    painted_mask = alpha_test > 0.1
    if painted_mask.any():
        L_white = 1.0  # white canvas luminance
        L_test = 0.2126 * canvas_test[..., 0] + 0.7152 * canvas_test[..., 1] + 0.0722 * canvas_test[..., 2]
        L_painted = L_test[painted_mask].mean()
        center_drop = float(L_white - L_painted)
    else:
        center_drop = 0.0
    
    return {
        'psnr': float(psnr),
        'ssim': float(ssim),
        'delta_e_mean': delta_e_mean,
        'coverage': float(coverage),
        'center_luminance_drop': center_drop
    }


def validate_metrics(metrics_dict: Dict[str, float], test_name: str):
    """Validate metrics against thresholds.
    
    Parameters
    ----------
    metrics_dict : dict
        Computed metrics
    test_name : str
        Test case name
    
    Raises
    ------
    AssertionError
        If any metric exceeds threshold
    """
    psnr = metrics_dict['psnr']
    ssim = metrics_dict['ssim']
    delta_e = metrics_dict['delta_e_mean']
    coverage = metrics_dict['coverage']
    center_drop = metrics_dict.get('center_luminance_drop', 0.0)
    
    logger.info(
        f"{test_name}: PSNR={psnr:.2f} dB, SSIM={ssim:.4f}, ΔE={delta_e:.2f}, "
        f"coverage={coverage:.4f}, center_drop={center_drop:.3f}"
    )
    
    assert psnr >= THRESHOLDS['psnr_min'], \
        f"PSNR {psnr:.2f} < {THRESHOLDS['psnr_min']} dB"
    
    assert ssim >= THRESHOLDS['ssim_min'], \
        f"SSIM {ssim:.4f} < {THRESHOLDS['ssim_min']}"
    
    assert delta_e <= THRESHOLDS['delta_e_max'], \
        f"ΔE {delta_e:.2f} > {THRESHOLDS['delta_e_max']}"
    
    assert center_drop >= THRESHOLDS['min_center_luminance_drop'], \
        f"Center luminance drop {center_drop:.3f} < {THRESHOLDS['min_center_luminance_drop']}"


# ============================================================================
# GOLDEN IMAGE TESTS
# ============================================================================

@pytest.mark.golden
def test_golden_straight_line(renderer, blank_canvas):
    """Golden test: straight horizontal line."""
    strokes = get_golden_strokes()
    stroke = strokes['straight_line']
    
    canvas, alpha = render_golden_case(renderer, stroke, *blank_canvas)
    
    # Path to golden image
    golden_path = GOLDEN_DIR / 'straight_line.png'
    
    # Regenerate golden (manual mode, not in CI)
    if not golden_path.exists():
        fs.ensure_dir(GOLDEN_DIR)
        save_golden_image(canvas, golden_path)
        pytest.skip(f"Generated golden image: {golden_path}")
    
    # Load golden
    canvas_golden = load_golden_image(golden_path)
    
    # Compute and validate metrics
    metrics_dict = compute_metrics(canvas, canvas_golden, alpha)
    validate_metrics(metrics_dict, 'straight_line')


@pytest.mark.golden
def test_golden_curved_stroke(renderer, blank_canvas):
    """Golden test: S-curve with varying z/v."""
    strokes = get_golden_strokes()
    stroke = strokes['curved_stroke']
    
    canvas, alpha = render_golden_case(renderer, stroke, *blank_canvas)
    
    golden_path = GOLDEN_DIR / 'curved_stroke.png'
    
    if not golden_path.exists():
        fs.ensure_dir(GOLDEN_DIR)
        save_golden_image(canvas, golden_path)
        pytest.skip(f"Generated golden image: {golden_path}")
    
    canvas_golden = load_golden_image(golden_path)
    metrics_dict = compute_metrics(canvas, canvas_golden, alpha)
    validate_metrics(metrics_dict, 'curved_stroke')


@pytest.mark.golden
def test_golden_multi_stroke(renderer, blank_canvas):
    """Golden test: three overlapping strokes (CMY layering)."""
    strokes = get_golden_multi_strokes()
    
    canvas, alpha = render_golden_case(renderer, strokes, *blank_canvas)
    
    golden_path = GOLDEN_DIR / 'multi_stroke.png'
    
    if not golden_path.exists():
        fs.ensure_dir(GOLDEN_DIR)
        save_golden_image(canvas, golden_path)
        pytest.skip(f"Generated golden image: {golden_path}")
    
    canvas_golden = load_golden_image(golden_path)
    metrics_dict = compute_metrics(canvas, canvas_golden, alpha)
    validate_metrics(metrics_dict, 'multi_stroke')


@pytest.mark.golden
def test_golden_boundary_graze(renderer, blank_canvas):
    """Golden test: stroke near canvas edge."""
    strokes = get_golden_strokes()
    stroke = strokes['boundary_graze']
    
    canvas, alpha = render_golden_case(renderer, stroke, *blank_canvas)
    
    golden_path = GOLDEN_DIR / 'boundary_graze.png'
    
    if not golden_path.exists():
        fs.ensure_dir(GOLDEN_DIR)
        save_golden_image(canvas, golden_path)
        pytest.skip(f"Generated golden image: {golden_path}")
    
    canvas_golden = load_golden_image(golden_path)
    metrics_dict = compute_metrics(canvas, canvas_golden, alpha)
    validate_metrics(metrics_dict, 'boundary_graze')


@pytest.mark.golden
def test_golden_tiny_stroke(renderer, blank_canvas):
    """Golden test: micro-stroke for anti-aliasing validation."""
    strokes = get_golden_strokes()
    stroke = strokes['tiny_stroke']
    
    canvas, alpha = render_golden_case(renderer, stroke, *blank_canvas)
    
    golden_path = GOLDEN_DIR / 'tiny_stroke.png'
    
    if not golden_path.exists():
        fs.ensure_dir(GOLDEN_DIR)
        save_golden_image(canvas, golden_path)
        pytest.skip(f"Generated golden image: {golden_path}")
    
    canvas_golden = load_golden_image(golden_path)
    metrics_dict = compute_metrics(canvas, canvas_golden, alpha)
    validate_metrics(metrics_dict, 'tiny_stroke')


# ============================================================================
# PHYSICS & VISIBILITY TESTS
# ============================================================================

@pytest.mark.physics
def test_visibility_sanity(renderer, blank_canvas):
    """Test that strokes are actually visible (not near-white)."""
    strokes = get_golden_strokes()
    
    # Test at moderate z, v
    stroke = strokes['straight_line']
    canvas, alpha = render_golden_case(renderer, stroke, *blank_canvas)
    
    # Check coverage
    coverage = np.mean(alpha)
    assert coverage >= 0.001, f"Coverage {coverage:.6f} too low (stroke nearly invisible)"
    
    # Check center luminance drop
    painted_mask = alpha > 0.1
    assert painted_mask.any(), "No pixels with alpha > 0.1"
    
    L = 0.2126 * canvas[..., 0] + 0.7152 * canvas[..., 1] + 0.0722 * canvas[..., 2]
    L_painted = L[painted_mask].mean()
    drop = 1.0 - L_painted
    
    assert drop >= 0.05, f"Center luminance drop {drop:.3f} < 0.05 (stroke barely visible)"


@pytest.mark.physics
def test_width_control(renderer, blank_canvas):
    """Test that width increases with Z as configured."""
    strokes = get_golden_strokes()
    
    # Low Z → narrow
    stroke_low = strokes['narrow_stroke_low_z']
    canvas_low, alpha_low = render_golden_case(renderer, stroke_low, *blank_canvas)
    
    # High Z → wide
    canvas_high = np.ones_like(blank_canvas[0])
    alpha_high = np.zeros_like(blank_canvas[1])
    stroke_high = strokes['wide_stroke_high_z']
    canvas_high, alpha_high = render_golden_case(renderer, stroke_high, canvas_high, alpha_high)
    
    # Measure "width" by counting pixels with alpha > 0.05 in cross-section
    # Find a vertical slice near the middle
    mid_x = 105 * (1280 // 210)  # x ≈ 105 mm
    
    width_low_px = np.sum(alpha_low[:, mid_x - 5:mid_x + 5] > 0.05)
    width_high_px = np.sum(alpha_high[:, mid_x - 5:mid_x + 5] > 0.05)
    
    assert width_high_px > width_low_px, \
        f"High Z width {width_high_px} px not > low Z width {width_low_px} px"


@pytest.mark.physics
def test_speed_scaling(renderer, blank_canvas):
    """Test that doubling speed reduces coverage (mass per mm halves)."""
    strokes = get_golden_strokes()
    
    # Slow stroke
    canvas_slow = np.ones_like(blank_canvas[0])
    alpha_slow = np.zeros_like(blank_canvas[1])
    stroke_slow = strokes['slow_stroke']
    canvas_slow, alpha_slow = render_golden_case(renderer, stroke_slow, canvas_slow, alpha_slow)
    coverage_slow = np.mean(alpha_slow)
    
    # Fast stroke
    canvas_fast = np.ones_like(blank_canvas[0])
    alpha_fast = np.zeros_like(blank_canvas[1])
    stroke_fast = strokes['fast_stroke']
    canvas_fast, alpha_fast = render_golden_case(renderer, stroke_fast, canvas_fast, alpha_fast)
    coverage_fast = np.mean(alpha_fast)
    
    # Fast should have less coverage (less ink per mm)
    assert coverage_fast < coverage_slow, \
        f"Fast coverage {coverage_fast:.4f} not < slow coverage {coverage_slow:.4f}"
    
    # Should be roughly 10x difference (200 vs 20 mm/s)
    # Alcohol ink model has stronger speed dependence
    ratio = coverage_slow / max(coverage_fast, 1e-9)
    assert 3.0 < ratio < 20.0, \
        f"Coverage ratio {ratio:.2f} outside expected range [3, 20]"


@pytest.mark.physics
def test_determinism(renderer):
    """Test that rendering is deterministic across runs."""
    stroke = get_golden_strokes()['straight_line']
    
    canvases = []
    for _ in range(3):
        canvas = np.ones((908, 1280, 3), dtype=np.float32)
        alpha = np.zeros((908, 1280), dtype=np.float32)
        canvas, _ = renderer.render_stroke(canvas, alpha, stroke)
        canvases.append(canvas.copy())
    
    # All runs should be identical
    for i in range(1, 3):
        assert np.allclose(canvases[0], canvases[i], atol=1e-7), \
            f"Run {i} differs from run 0 (non-deterministic)"


@pytest.mark.physics
def test_layering_alpha_over(renderer):
    """Test that yellow over green produces yellowish-green (alpha-over)."""
    # Green stroke
    canvas = np.ones((908, 1280, 3), dtype=np.float32)
    alpha = np.zeros((908, 1280), dtype=np.float32)
    
    stroke_green = {
        'id': 'layer-green',
        'bezier': {
            'p1': (80.0, 150.0),
            'p2': (100.0, 150.0),
            'p3': (120.0, 150.0),
            'p4': (140.0, 150.0)
        },
        'z_profile': {'z0': 6.0, 'z1': 6.0},
        'speed_profile': {'v0': 50.0, 'v1': 50.0},
        'color_cmy': {'c': 1.0, 'm': 0.0, 'y': 1.0}  # green = C+Y
    }
    
    canvas, alpha = renderer.render_stroke(canvas, alpha, stroke_green)
    
    # Find center pixel
    center_x = 110 * (1280 // 210)
    center_y = 150 * (908 // 297)
    color_green = canvas[center_y, center_x]
    
    # Yellow stroke over green
    stroke_yellow = {
        'id': 'layer-yellow',
        'bezier': {
            'p1': (80.0, 150.0),
            'p2': (100.0, 150.0),
            'p3': (120.0, 150.0),
            'p4': (140.0, 150.0)
        },
        'z_profile': {'z0': 6.0, 'z1': 6.0},
        'speed_profile': {'v0': 50.0, 'v1': 50.0},
        'color_cmy': {'c': 0.0, 'm': 0.0, 'y': 1.0}  # yellow
    }
    
    canvas, alpha = renderer.render_stroke(canvas, alpha, stroke_yellow)
    color_result = canvas[center_y, center_x]
    
    # Result should be more yellowish (higher R, G) than pure green
    assert color_result[1] >= color_green[1], \
        "Yellow over green should increase G (more yellowish)"


@pytest.mark.physics
def test_coverage_stability(renderer):
    """Test that coverage metrics are stable across runs."""
    stroke = get_golden_strokes()['straight_line']
    
    coverages = []
    for _ in range(3):
        canvas = np.ones((908, 1280, 3), dtype=np.float32)
        alpha = np.zeros((908, 1280), dtype=np.float32)
        
        canvas, alpha = renderer.render_stroke(canvas, alpha, stroke)
        alpha_torch = torch.from_numpy(alpha)
        coverage = metrics.paint_coverage(alpha_torch)
        coverages.append(coverage.item())
    
    # All runs should give identical coverage
    assert all(abs(c - coverages[0]) < 1e-7 for c in coverages), \
        f"Coverage not deterministic: {coverages}"


# ============================================================================
# METADATA & THRESHOLDS
# ============================================================================

def test_golden_thresholds_yaml_exists():
    """Test that golden thresholds YAML exists and is valid."""
    thresholds_path = GOLDEN_DIR / 'thresholds.yaml'
    
    if not thresholds_path.exists():
        # Create default thresholds
        fs.ensure_dir(GOLDEN_DIR)
        fs.atomic_yaml_dump(THRESHOLDS, thresholds_path)
        pytest.skip(f"Generated thresholds: {thresholds_path}")
    
    # Load and validate
    loaded = fs.load_yaml(thresholds_path)
    assert 'psnr_min' in loaded
    assert 'ssim_min' in loaded
    assert 'delta_e_max' in loaded
    assert loaded['psnr_min'] > 0


# ============================================================================
# RUN TESTS
# ============================================================================

if __name__ == '__main__':
    pytest.main([__file__, '-v', '--tb=short', '-m', 'golden or physics'])
