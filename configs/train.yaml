# Training configuration
# Used by: scripts/train.py
# Purpose: Global training & compute settings for PPO agent

task: "AirbrushPainter-v0"
device: "cuda:0"

# DGX Spark defaults (Grace Hopper, Blackwell Tensor Cores)
compute:
  precision: "bf16"              # BF16 for networks, FP32 for LUTs/LPIPS
  channels_last: true            # Free CNN performance
  grad_checkpointing: false      # DGX has headroom; prioritize speed
  torch_compile:
    enabled: false               # Enable after stability confirmed
    mode: "max-autotune"

# Environment and simulation configs (paths)
env_config: "configs/env_airbrush_v1.yaml"
sim_config: "configs/sim/physics_v1.yaml"

# LPIPS configuration
lpips:
  net: "vgg"                     # "vgg" or "alex"
  tile:
    size: 0                      # 0 = full-frame on DGX; reduce if OOM (e.g., 2048)
    overlap: 0

# PPO hyperparameters
agent:
  backbone: "resnet34"                      # Network architecture
  spatial_head: "heatmap_soft_argmax"       # "coordconv" or "heatmap_soft_argmax"
  softargmax_temp: 1.0                      # Temperature (lower=sharper, higher=smoother)
  learning_rate: 0.0003
  entropy_coef: 0.001
  gamma: 0.995                              # Discount factor
  clip_param: 0.2                           # PPO clipping

# Content curriculum (no resolution curriculum, multi-resolution is architectural)
curriculum:
  stage: "hard"                  # "easy", "medium", or "hard"

# Dataloader
dataloader:
  pin_memory: false              # UMA (unified memory architecture)

# Logging and MLflow
logging:
  level: "INFO"
  json: false
  color: true
  file: "outputs/logs/train.log"
  rotate:
    mode: "size"
    max_bytes: 50000000          # 50 MB
    backup_count: 5
  capture_warnings: true
  quiet_libs: ["matplotlib", "PIL", "numba", "urllib3"]
  context:
    app: "train"
  mlflow_experiment: "airbrush_train_v2"
  run_name_prefix: "train"
  log_seeds: true                # Log PYTHONHASHSEED, torch seeds, cudnn flags
  save_interval: 10              # Save training monitor artifacts every N epochs

